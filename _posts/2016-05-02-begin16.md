---
title: PAC-Bayesian Bounds based on the Rényi Divergence
abstract: We propose a simplified proof process for PAC-Bayesian generalization bounds,
  that allows to divide the proof in four successive inequalities, easing the "customization"
  of PAC-Bayesian theorems. We also propose a family of PAC-Bayesian bounds based
  on the Rényi divergence between the prior and posterior distributions, whereas most
  PAC-Bayesian bounds are based on the Kullback-Leibler divergence. Finally, we present
  an empirical evaluation of the tightness of each inequality of the simplified proof,
  for both the classical PAC-Bayesian bounds and those based on the Rényi divergence.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: begin16
month: 0
tex_title: PAC-Bayesian Bounds based on the Rényi Divergence
firstpage: 435
lastpage: 444
page: 435-444
order: 435
cycles: false
author:
- given: Luc
  family: Bégin
- given: Pascal
  family: Germain
- given: François
  family: Laviolette
- given: Jean-Francis
  family: Roy
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/begin16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
