---
supplementary: http://proceedings.mlr.press/v51/camoriano16-supp.pdf
title: 'NYTRO: When Subsampling Meets Early Stopping'
abstract: Early stopping is a well known approach to reduce the time complexity for
  performing training and model selection of large scale learning machines. On the
  other hand,  memory/space (rather than time) complexity is the main constraint in
  many applications, and randomized subsampling techniques have been proposed to tackle
  this issue. In this paper we ask whether early stopping and subsampling ideas can
  be combined in a fruitful way. We consider the question in a least squares regression
  setting and propose a form of randomized iterative regularization based on early
  stopping and subsampling. In this context, we analyze the statistical and computational
  properties of the proposed method. Theoretical results are complemented and validated
  by a thorough experimental analysis.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: camoriano16
month: 0
tex_title: 'NYTRO: When Subsampling Meets Early Stopping'
firstpage: 1403
lastpage: 1411
page: 1403-1411
order: 1403
cycles: false
author:
- given: Raffaello
  family: Camoriano
- given: Tom√°s
  family: Angles
- given: Alessandro
  family: Rudi
- given: Lorenzo
  family: Rosasco
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/camoriano16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
