---
title: Online Relative Entropy Policy Search using Reproducing Kernel Hilbert Space
  Embeddings
abstract: Kernel methods have been successfully applied to reinforcement learning
  problems to address some challenges such as high dimensional and continuous states,
  value function approximation and state transition probability modeling. In this
  paper, we develop an online policy search algorithm based on a recent state-of-the-art
  algorithm REPS-RKHS that uses conditional kernel embeddings. Our online algorithm
  inherits the advantages of REPS-RKHS, including the ability to learn non-parametric
  control policies for infinite horizon continuous MDPs with high- dimensional sensory
  representations. Different from the original REPS-RKHS algorithm which is based
  on batch learning, the proposed online algorithm updates the model in an online
  fashion and thus is able to capture and respond to rapid changes in the system dynamics.
  In addition, the online update operation takes constant time (i.e., independent
  of the sample size n), which is much more efficient computationally and allows the
  policy to be continuously revised. Experiments on different domains are conducted
  and results show that our online algorithm outperforms the original algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chen16a
month: 0
tex_title: Online Relative Entropy Policy Search using Reproducing Kernel Hilbert
  Space Embeddings
firstpage: 573
lastpage: 581
page: 573-581
order: 573
cycles: false
author:
- given: Zhitang
  family: Chen
- given: Pascal
  family: Poupart
- given: Yanhui
  family: Geng
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/chen16a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
