---
supplementary: Supplementary:cheng16-supp.pdf
title: Scalable and Sound Low-Rank Tensor Learning
abstract: Many real-world data arise naturally as tensors. Equipped with a low rank
  prior, learning algorithms can benefit from exploiting the rich dependency encoded
  in a tensor. Despite its prevalence in low-rank matrix learning, trace norm ceases
  to be tractable in tensors and therefore most existing works resort to matrix unfolding.
  Although some theoretical guarantees are available, these approaches may lose valuable
  structure information and are not scalable in general. To address this problem,
  we propose directly optimizing the tensor trace norm by approximating its dual spectral
  norm, and we show that the approximation bounds can be efficiently converted to
  the original problem via the generalized conditional gradient algorithm. The resulting
  approach is scalable to large datasets, and matches state-of-the-art recovery guarantees.
  Experimental results on tensor completion and multitask learning confirm the superiority
  of the proposed method.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheng16
month: 0
firstpage: 1114
lastpage: 1123
page: 1114-1123
sections: 
author:
- given: Hao
  family: Cheng
- given: Yaoliang
  family: Yu
- given: Xinhua
  family: Zhang
- given: Eric
  family: Xing
- given: Dale
  family: Schuurmans
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/cheng16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
