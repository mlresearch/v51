---
supplementary: http://proceedings.mlr.press/v51/hernandez-lobato16-supp.zip
title: Scalable Gaussian Process Classification via Expectation Propagation
abstract: Variational methods have been recently considered for scaling the training
  process of Gaussian process classifiers to large datasets. As an alternative, we
  describe here how to train these classifiers efficiently using expectation propagation
  (EP). The proposed EP method allows to train Gaussian process classifiers on very
  large datasets, with millions of instances, that were out of the reach of previous
  implementations of EP. More precisely, it can be used for (i) training in a distributed
  fashion where the data instances are sent to different nodes in which the required
  computations are carried out, and for (ii) maximizing an estimate of the marginal
  likelihood using a stochastic approximation of the gradient. Several experiments
  involving large datasets show that the method described is competitive with the
  variational approach.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hernandez-lobato16
month: 0
tex_title: Scalable Gaussian Process Classification via Expectation Propagation
firstpage: 168
lastpage: 176
page: 168-176
order: 168
cycles: false
author:
- given: Daniel
  family: Hernandez-Lobato
- given: Jose Miguel
  family: Hernandez-Lobato
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/hernandez-lobato16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
