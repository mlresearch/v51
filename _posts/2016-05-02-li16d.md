---
title: Scalable MCMC for Mixed Membership Stochastic Blockmodels
abstract: We propose a stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithm
  for scalable inference in mixed-membership stochastic blockmodels (MMSB). Our algorithm
  is based on the stochastic gradient Riemannian Langevin sampler and achieves both
  faster speed and higher accuracy at every iteration than the current state-of-the-art
  algorithm based on stochastic variational inference. In addition we develop an approximation
  that can handle models that entertain a very large number of communities. The experimental
  results show that SG-MCMC strictly dominates competing algorithms in all cases.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: li16d
month: 0
firstpage: 723
lastpage: 731
page: 723-731
sections: 
author:
- given: Wenzhe
  family: Li
- given: Sungjin
  family: Ahn
- given: Max
  family: Welling
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/li16d.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
