---
title: A Linearly-Convergent Stochastic L-BFGS Algorithm
abstract: We propose a new stochastic L-BFGS algorithm and prove a linear convergence
  rate for strongly convex and smooth functions. Our algorithm draws heavily from
  a recent stochastic variant of L-BFGS proposed in Byrd et al. (2014) as well as
  a recent approach to variance reduction for stochastic gradient descent from Johnson
  and Zhang (2013). We demonstrate experimentally that our algorithm performs well
  on large-scale convex and non-convex optimization problems, exhibiting linear convergence
  and rapidly solving the optimization problems to high levels of precision. Furthermore,
  we show that our algorithm performs well for a wide-range of step sizes, often differing
  by several orders of magnitude.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: moritz16
month: 0
tex_title: A Linearly-Convergent Stochastic L-BFGS Algorithm
firstpage: 249
lastpage: 258
page: 249-258
sections: 
author:
- given: Philipp
  family: Moritz
- given: Robert
  family: Nishihara
- given: Michael
  family: Jordan
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/moritz16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
