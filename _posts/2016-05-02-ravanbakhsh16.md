---
title: Stochastic Neural Networks with Monotonic Activation Functions
abstract: We propose a Laplace approximation that creates a stochastic unit from any
  smooth monotonic activation function, using only Gaussian noise. This paper investigates
  the application of this stochastic approximation in training a family of Restricted
  Boltzmann Machines (RBM) that are closely linked to Bregman divergences. This family,
  that we call exponential family RBM (Exp-RBM), is a subset of the exponential family
  Harmoniums that expresses family members through a choice of smooth monotonic non-linearity
  for each neuron. Using contrastive divergence along with our Gaussian approximation,
  we show that Exp-RBM can learn useful representations using novel stochastic units.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ravanbakhsh16
month: 0
firstpage: 809
lastpage: 818
page: 809-818
sections: 
author:
- given: Siamak
  family: Ravanbakhsh
- given: Barnabas
  family: Poczos
- given: Jeff
  family: Schneider
- given: Dale
  family: Schuurmans
- given: Russell
  family: Greiner
date: 2016-05-02
address: Cadiz, Spain
publisher: PMLR
container-title: Proceedings of the 19th International Conference on Artificial Intelligence
  and Statistics
volume: '51'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 5
  - 2
pdf: http://proceedings.mlr.press/v51/ravanbakhsh16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
