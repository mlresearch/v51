<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Provable Tensor Methods for Learning Mixtures of Generalized Linear Models | AISTATS 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Provable Tensor Methods for Learning Mixtures of Generalized Linear Models">

  <meta name="citation_author" content="Sedghi, Hanie">

  <meta name="citation_author" content="Janzamin, Majid">

  <meta name="citation_author" content="Anandkumar, Anima">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of the 19th International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="1223">
<meta name="citation_lastpage" content="1231">
<meta name="citation_pdf_url" content="sedghi16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Provable Tensor Methods for Learning Mixtures of Generalized Linear Models</h1>

	<div id="authors">
	
		Hanie Sedghi,
	
		Majid Janzamin,
	
		Anima Anandkumar
	<br />
	</div>
	<div id="info">
		Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,
		pp. 1223â€“1231, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We consider the problem of learning mixtures of generalized linear models (GLM) which arise in classification and regression problems. Typical learning approaches such as expectation maximization (EM) or variational Bayes can get stuck in spurious local optima. In contrast, we present a tensor decomposition method which is guaranteed to correctly recover the parameters. The key insight is to employ certain feature transformations of the input, which depend on the input generative model. Specifically, we employ score function tensors of the input and compute their cross-correlation with the response variable. We establish that the decomposition of this tensor consistently recovers the parameters, under mild non-degeneracy conditions. We demonstrate that the computational and sample complexity of our method is a low order polynomial of the input and the latent dimensions.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="sedghi16.pdf">Download PDF</a></li>
			
			<li><a href="sedghi16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
