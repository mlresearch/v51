<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>On Lloyd’s Algorithm: New Theoretical Insights for Clustering in Practice | AISTATS 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="On Lloyd's Algorithm: New Theoretical Insights for Clustering in Practice">

  <meta name="citation_author" content="Tang, Cheng">

  <meta name="citation_author" content="Monteleoni, Claire">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of the 19th International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="1280">
<meta name="citation_lastpage" content="1289">
<meta name="citation_pdf_url" content="tang16b.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>On Lloyd’s Algorithm: New Theoretical Insights for Clustering in Practice</h1>

	<div id="authors">
	
		Cheng Tang,
	
		Claire Monteleoni
	<br />
	</div>
	<div id="info">
		Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,
		pp. 1280–1289, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We provide new analyses of Lloyd’s algorithm (1982), commonly known as the <span class="math">\(k\)</span>-means clustering algorithm. Kumar and Kannan (2010) showed that running <span class="math">\(k\)</span>-SVD followed by a constant approximation <span class="math">\(k\)</span>-means algorithm, and then Lloyd’s algorithm, will correctly cluster nearly all of the dataset with respect to the optimal clustering, provided the dataset satisfies a deterministic clusterability assumption. This method is viewed as the “Swiss Army knife” for clustering problems, subsuming popular generative models such as Gaussian mixtures. However, it is tailored to high dimensional data, i.e., when <span class="math">\(d \gg k\)</span> . We analyze Lloyd’s algorithm for general d without using the spectral projection, which leads to a weaker assumption in the case <span class="math">\(d &lt; k\)</span>. Surprisingly, we show that a simple and scalable heuristic that combines random sampling with Single-Linkage serves as a good seeding algorithm for Lloyd’s algorithm under this assumption. We then study stopping criteria for Lloyd’s algorithm under the lens of clusterability, accompanied by controlled simulations.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="tang16b.pdf">Download PDF</a></li>
			
			<li><a href="tang16b-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
