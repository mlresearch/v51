<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Black-Box Policy Search with Probabilistic Programs | AISTATS 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Black-Box Policy Search with Probabilistic Programs">

  <meta name="citation_author" content="Vandemeent, Jan-Willem">

  <meta name="citation_author" content="Paige, Brooks">

  <meta name="citation_author" content="Tolpin, David">

  <meta name="citation_author" content="Wood, Frank">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of the 19th International Conference on Artificial Intelligence and Statistics">
<meta name="citation_firstpage" content="1195">
<meta name="citation_lastpage" content="1204">
<meta name="citation_pdf_url" content="vandemeent16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Black-Box Policy Search with Probabilistic Programs</h1>

	<div id="authors">
	
		Jan-Willem Vandemeent,
	
		Brooks Paige,
	
		David Tolpin,
	
		Frank Wood
	<br />
	</div>
	<div id="info">
		Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,
		pp. 1195â€“1204, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In this work we show how to represent policies as programs: that is, as stochastic simulators with tunable parameters. To learn the parameters of such policies we develop connections between black box variational inference and existing policy search approaches. We then explain how such learning can be implemented in a probabilistic programming system. Using our own novel implementation of such a system we demonstrate both conciseness of policy representation and automatic policy parameter learning for a set of canonical reinforcement learning problems.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="vandemeent16.pdf">Download PDF</a></li>
			
			<li><a href="vandemeent16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
